
# %% Load and prepare BALANCED dataset
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import glob
import os
from collections import defaultdict

dronerf_path = r"C:\PRML\DroneRF_Dataset\DroneRF"

def load_rf_signal_fast(file_path, n_samples=50000):
    """Quick load for feature extraction"""
    with open(file_path, 'r') as f:
        data_line = f.readline().strip()
    values = data_line.split(',')[:n_samples]
    return np.array([float(v) for v in values])

def extract_time_domain_features(signal):
    """Extract simple time-domain features for Naive Bayes"""
    return np.array([
        np.sum(signal**2),                          # signal_energy
        np.sqrt(np.mean(signal**2)),                # rms_amplitude
        np.sum(np.diff(np.sign(signal)) != 0) / len(signal),  # zero_crossing_rate
        np.max(signal) - np.min(signal),            # peak_to_peak
        np.mean(np.abs(signal)),                    # mean_abs
        np.std(signal)                              # std
    ])

print("="*70)
print("NAIVE BAYES: BALANCED DATASET PREPARATION")
print("="*70)

# Get all files
csv_files = glob.glob(os.path.join(dronerf_path, '**', '*.csv'), recursive=True)

# Categorize by drone type and mode
drone_categories = defaultdict(list)
background_files = []

for file_path in csv_files:
    if 'background' in file_path.lower():
        background_files.append(file_path)
    else:
        # Extract drone type from path (AR=101, Bebop=100, Phantom=110)
        # and mode from filename pattern
        parent_folder = file_path.split(os.sep)[-2]  # Get parent folder name
        drone_categories[parent_folder].append(file_path)

# Show distribution
print("\nDataset Distribution:")
print(f"Background: {len(background_files)} files")
for category, files in sorted(drone_categories.items()):
    print(f"{category}: {len(files)} files")

# Balanced sampling: take equal samples from each category
samples_per_category = 5  # Adjust based on time/memory constraints
total_drone_categories = len(drone_categories)

sample_files = []
category_labels = []

# Sample from each drone category
for category, files in drone_categories.items():
    sampled = files[:min(samples_per_category, len(files))]
    sample_files.extend(sampled)
    category_labels.extend([category] * len(sampled))

# Sample from background (match total drone samples)
n_background = len(sample_files)
background_sampled = background_files[:min(n_background, len(background_files))]
sample_files.extend(background_sampled)
category_labels.extend(['Background'] * len(background_sampled))

print(f"\nðŸ“Š Balanced Sample:")
print(f"Total files: {len(sample_files)}")
for cat in set(category_labels):
    count = category_labels.count(cat)
    print(f"  {cat}: {count} files")

print("\nExtracting features...")

X_list = []
y_list = []

for i, file_path in enumerate(sample_files):
    if i % 10 == 0:
        print(f"Processing {i+1}/{len(sample_files)}...")
    
    # Load signal
    signal = load_rf_signal_fast(file_path, n_samples=50000)
    
    # Extract features
    features = extract_time_domain_features(signal)
    
    # Label
    label = 1 if 'background' not in file_path.lower() else 0
    
    X_list.append(features)
    y_list.append(label)

X = np.array(X_list)
y = np.array(y_list)

print(f"\nâœ… Feature extraction complete")
print(f"Feature matrix shape: {X.shape}")
# %% data split & model training
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTrain set: {X_train.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

#train Naive Bayes

print("\n" + "="*70)
print("TRAINING NAIVE BAYES CLASSIFIER")
print("="*70)

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

print("âœ… Training complete")
# %%
from sklearn.metrics import precision_score, recall_score, f1_score
y_pred = nb_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
F1Score = f1_score(y_test, y_pred, average='weighted')
print(f"\nðŸŽ¯ Test Accuracy: {accuracy:.2%}")
print(f"\nðŸŽ¯ Test Precision: {precision:.2%}")
print(f"\nðŸŽ¯ Test Recall: {recall:.2%}")
print(f"\nðŸŽ¯ Test F1-Score: {F1Score:.2%}")

print("\nðŸ“Š Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Background', 'Drone']))

print("\nðŸ“‹ Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(f"\nTrue Negatives: {cm[0,0]}, False Positives: {cm[0,1]}")
print(f"False Negatives: {cm[1,0]}, True Positives: {cm[1,1]}")

print("\n" + "="*70)
print(f"NAIVE BAYES BASELINE: {accuracy:.2%} ACCURACY")
print("="*70)
# %%
import sklearn.metrics
print(dir(sklearn.metrics))
# %%
